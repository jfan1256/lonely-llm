alpha: 0.97
alpha_center: 0.5
alpha_focal: 0.7
alpha_tverksy: 0.2
batch_size: 8
bert_config: ../configs/model/bert_base.json
bert_layer_train: none
bert_lr: 1.0e-05
bert_model: bert-base-uncased
bert_model_checkpoint: ../store_model/bert_corpus_checkpoint_30.pth
beta_tversky: 0.8
early_stop: 5
embed_type: document
eval_device: cuda:0
gamma_focal: 2
loss:
- loss_ce
margin_contrast: 1.0
margin_lmcl: 0.35
max_epoch: 100
min_lr: 0
mlp_lr: 3.0e-05
num_class: 2
num_gpu: 1
output_dir: ../paper_experiment/loneliness/corpus_bert_mlp_no_last
package: gloo
prompt: ''
test_path: ../data/loneliness/OurLabeledData/SamplingData-1/loneliness-test-1_gpt4o_improved.csv
train_checkpoint: ''
train_device: cuda:0
train_path: ../data/loneliness/OurLabeledData/SamplingData-1/loneliness-train-1_gpt4o_improved.csv
val_path: ../data/loneliness/OurLabeledData/SamplingData-1/loneliness-val-1_gpt4o_improved.csv
weight_decay: 0.05
